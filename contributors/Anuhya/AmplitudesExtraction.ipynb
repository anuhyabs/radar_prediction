{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb6d7300-ba99-42df-a727-bcc568efa206",
   "metadata": {},
   "outputs": [],
   "source": [
    "from snowexsql.db import get_db\n",
    "from snowexsql.data import ImageData, SiteData, LayerData\n",
    "from rasterio.plot import show\n",
    "from sqlalchemy.sql import func\n",
    "import geoalchemy2.functions as gfunc\n",
    "from geoalchemy2.types import Raster\n",
    "from geoalchemy2.shape import to_shape\n",
    "import geopandas as gpd\n",
    "from snowexsql.conversions import raster_to_rasterio\n",
    "from snowexsql.conversions import points_to_geopandas, query_to_geopandas, query_to_pandas\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from datetime import date\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9028049-d194-410c-a444-533e1209c2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bufferedPit(pit_id):\n",
    "    # Distance around the pit to collect data in meters\n",
    "    buffer_dist = 50\n",
    "\n",
    "    datasets = []\n",
    "\n",
    "    # Grab our sites details by site id\n",
    "    q = session.query(LayerData).filter(LayerData.pit_id==pit_id)\n",
    "    sites = q.all()\n",
    "\n",
    "    # Grab the pit location from a single layer\n",
    "    p = sites[0].geom\n",
    "\n",
    "    # Convert the point to a pyshapely\n",
    "    pit = to_shape(p)\n",
    "\n",
    "    # Convert it to a geopandas dataframe for easy plotting\n",
    "    df_pit = gpd.GeoSeries(pit)\n",
    "    q = session.query(gfunc.ST_Buffer(p, buffer_dist))\n",
    "    buffered_pit = q.all()[0][0]\n",
    "    return buffered_pit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd2698b3-9c39-4fbc-beab-475a58334d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_amplitudes(raster):\n",
    "    \"\"\"\n",
    "    input: 2 dimensional array of list of amplitudes over multiple rasters\n",
    "    output: average amplitude over entire raster\n",
    "    \"\"\"\n",
    "    #create a variable to average each individual raster\n",
    "    single_avgs = []\n",
    "    #iterate over all rasters\n",
    "    for i in range(len(raster)): \n",
    "        #compute and append the mean of the raster \n",
    "        single_avgs.append(sum(dataset.read(1)[i])/len(dataset.read(1)[i]))\n",
    "    \n",
    "    #compute the average amplitude over all rasters\n",
    "    avg_amp = sum(single_avgs)/len(single_avgs) \n",
    "    \n",
    "    return avg_amp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e294f7b9-64ee-4c32-b3fa-149300ed169b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_polarizations(csv1, csv2):\n",
    "    '''\n",
    "    Input: two csv name paths, each containing a pit_id and amplitude\n",
    "    \n",
    "    Output: Pandas dataframe containing pit_id's and average amperage between the two\n",
    "    \n",
    "    '''\n",
    "    #read in files\n",
    "    c1 = pd.read_csv(csv1)\n",
    "    c2 = pd.read_csv(csv2)\n",
    "    \n",
    "    #rename columns, remove unnamed index columns\n",
    "    c1 = c1[['0', '1']]\n",
    "    c1.columns = ['pit_id', 'c1_amp']\n",
    "    c2 = c2[['0', '1']]\n",
    "    c2.columns = ['pit_id', 'c2_amp']\n",
    "    \n",
    "    #merge together on pit_id\n",
    "    polars = c1.merge(c2, on=['pit_id'], how='left')\n",
    "    polars['avg_amp'] = (polars.c1_amp + polars.c2_amp) / 2\n",
    "    \n",
    "    return polars[['pit_id', 'avg_amp']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0a0a08f-03ae-4583-8fc3-605adf98637f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['0', '1'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 35>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     58\u001b[0m amp12 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(amplitudes_12)\n\u001b[1;32m     59\u001b[0m amp12\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mamplitudes_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 60\u001b[0m amplitudes_final \u001b[38;5;241m=\u001b[39m \u001b[43maverage_polarizations\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mamplitudes_\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mamplitudes_\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m2.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m amplitudes_final\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mamplitudes_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_final.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36maverage_polarizations\u001b[0;34m(csv1, csv2)\u001b[0m\n\u001b[1;32m     10\u001b[0m c2 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(csv2)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m#rename columns, remove unnamed index columns\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m c1 \u001b[38;5;241m=\u001b[39m \u001b[43mc1\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m0\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     14\u001b[0m c1\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpit_id\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mc1_amp\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     15\u001b[0m c2 \u001b[38;5;241m=\u001b[39m c2[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.10/site-packages/pandas/core/frame.py:3511\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3509\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   3510\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 3511\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   3513\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   3514\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.10/site-packages/pandas/core/indexes/base.py:5782\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   5779\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   5780\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 5782\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5784\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   5785\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   5786\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.10/site-packages/pandas/core/indexes/base.py:5842\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   5840\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m use_interval_msg:\n\u001b[1;32m   5841\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 5842\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   5844\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m   5845\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [Index(['0', '1'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "# Pit Site Identifier of interest\n",
    "site_name = 'Grand Mesa'\n",
    "\n",
    "# Connect to the database we made.\n",
    "db_name = 'snow:hackweek@db.snowexdata.org/snowex'\n",
    "engine, session = get_db(db_name)\n",
    "\n",
    "datasets_2 = []\n",
    "amplitudes_2 = []\n",
    "datasets_12 = []\n",
    "amplitudes_12 = []\n",
    "\n",
    "# Grab our sites details by site id\n",
    "#q = session.query(SiteData).filter(SiteData.site_id==site_id)\n",
    "q = session.query(SiteData.site_id).filter(SiteData.site_name==site_name)\n",
    "q = q.filter(SiteData.tree_canopy==\"No Trees\")\n",
    "q = q.filter(SiteData.date>=date(2020,1,28))\n",
    "q = q.filter(SiteData.date<=date(2020,3,1))\n",
    "sites = q.all()\n",
    "sites = [d[0] for d in sites] \n",
    "q_layer = session.query(LayerData.pit_id).filter(LayerData.site_id.in_(sites))\n",
    "q_layer = q_layer.distinct()\n",
    "df = query_to_pandas(q_layer, engine)\n",
    "df.sort_values(by=['pit_id'],ascending=True)\n",
    "\n",
    "# Grab the rasters, union them and convert them as tiff when done\n",
    "q_raster = session.query(func.ST_AsTiff(func.ST_Union(ImageData.raster, type_=Raster)))\n",
    "\n",
    "# Only grab rasters that are the bare earth DEM from USGS\n",
    "q_raster = q_raster.filter(ImageData.type == 'insar amplitude').filter(ImageData.observers=='UAVSAR team, JPL').filter(ImageData.site_name == \"Grand Mesa\")\n",
    "q_raster = q_raster.filter(ImageData.description.in_\n",
    "                           ([\"Overpass Duration: 2020-02-12 16:47:20 - 2020-02-12 16:49:45 (UTC), DEM used = Intermap Elevation Model DTM, Polarization = VV\"]))\n",
    "polarizations = ['HH','HV','VH','VV']\n",
    "\n",
    "for i in polarizations:\n",
    "    q_raster_2 = q_raster.filter(ImageData.description.in_\n",
    "                           ([\"Overpass Duration: 2020-02-01 02:13:16 - 2020-02-01 02:15:58 (UTC), DEM used = Intermap Elevation Model DTM, Polarization = \"+i]))\n",
    "    q_raster_12 = q_raster.filter(ImageData.description.in_\n",
    "                           ([\"Overpass Duration: 2020-02-12 16:47:20 - 2020-02-12 16:49:45 (UTC), DEM used = Intermap Elevation Model DTM, Polarization = \"+i]))\n",
    "    for id in df.pit_id:\n",
    "        try:\n",
    "            buffered_pit = get_bufferedPit(id)\n",
    "            q_raster_new_2 = q_raster_2.filter(gfunc.ST_Intersects(ImageData.raster, buffered_pit))\n",
    "            q_raster_new_12 = q_raster_12.filter(gfunc.ST_Intersects(ImageData.raster, buffered_pit))\n",
    "            rasters_2 = q_raster_new_2.all()\n",
    "            ratsers_12 = q_raster_new_12.all()\n",
    "            dataset_2 = raster_to_rasterio(session, rasters_2)[0]\n",
    "            dataset_12 = raster_to_rasterio(session, rasters_12)[0]\n",
    "            avg_amplitudes_2 = average_amplitudes(dataset_2.read(1))\n",
    "            avg_amplitudes_12 = average_amplitudes(dataset_12.read(1))\n",
    "            amplitudes_2.append((id,avg_amplitudes_2))\n",
    "            amplitudes_12.append((id,avg_amplitudes_12))\n",
    "        except TypeError:\n",
    "            #print(\"I failed\")\n",
    "            continue\n",
    "    amp2 = pd.DataFrame(amplitudes_2)\n",
    "    amp2.to_csv('amplitudes_'+i+'.csv')\n",
    "    amp12 = pd.DataFrame(amplitudes_12)\n",
    "    amp12.to_csv('amplitudes_'+i+'2.csv')\n",
    "    amplitudes_final = average_polarizations('amplitudes_'+i+'.csv','amplitudes_'+i+'2.csv')\n",
    "    amplitudes_final.to_csv('amplitudes_'+i+'_final.csv')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25acb4c6-d46c-45f8-a665-37e3a62328ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "polarizations = ['HH','HV','VH','VV']\n",
    "for i in polarizations:\n",
    "    q_raster = q_raster.filter(ImageData.description.in_\n",
    "                           ([\"Overpass Duration: 2020-02-01 02:13:16 - 2020-02-01 02:15:58 (UTC), DEM used = Intermap Elevation Model DTM, Polarization = \"+i,\n",
    "                           \"Overpass Duration: 2020-02-12 16:47:20 - 2020-02-12 16:49:45 (UTC), DEM used = Intermap Elevation Model DTM, Polarization = \"+i]))\n",
    "\n",
    "    for id in df.pit_id:\n",
    "        try:\n",
    "            buffered_pit = get_bufferedPit(id)\n",
    "            q_raster_new = q_raster.filter(gfunc.ST_Intersects(ImageData.raster, buffered_pit))\n",
    "            rasters = q_raster_new.all()\n",
    "            dataset = raster_to_rasterio(session, rasters)[0]\n",
    "            avg_amplitudes = average_amplitudes(dataset.read(1))\n",
    "            amplitudes.append((id,avg_amplitudes))\n",
    "        except TypeError:\n",
    "            #print(\"I failed\")\n",
    "            continue\n",
    "    print(i)\n",
    "    print(len(amplitudes))\n",
    "    amp = pd.DataFrame(amplitudes)\n",
    "    amp.to_csv('amplitudes_'+i+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2a6ed00e-7dc7-40d0-a108-847f62195388",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "amplitudes_final_VH = average_polarizations('amplitudes_VH.csv','amplitudes_VH2.csv')\n",
    "amplitudes_final_VV = average_polarizations('amplitudes_VV.csv','amplitudes_VV2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6c4ef058-15e1-4e13-a38f-2a77820df30b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pit_id</th>\n",
       "      <th>avg_amp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>COGM2S37_20200201</td>\n",
       "      <td>0.034575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>COGMSO_20200321_1006</td>\n",
       "      <td>0.054984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>COGM5S31_20200130</td>\n",
       "      <td>0.034575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>COGMCO_20200318_0825</td>\n",
       "      <td>0.047769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>COGM2C2_20200131</td>\n",
       "      <td>0.025515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>COGMSO_20200328_1630</td>\n",
       "      <td>0.054984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>COGMSO_20200406_0650</td>\n",
       "      <td>0.084845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>COGM1C7_20200131</td>\n",
       "      <td>0.031300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>COGM6C10_20200131</td>\n",
       "      <td>0.031300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>COGM1N23_20200211</td>\n",
       "      <td>0.036019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 pit_id   avg_amp\n",
       "0     COGM2S37_20200201  0.034575\n",
       "1  COGMSO_20200321_1006  0.054984\n",
       "2     COGM5S31_20200130  0.034575\n",
       "3  COGMCO_20200318_0825  0.047769\n",
       "4      COGM2C2_20200131  0.025515\n",
       "5  COGMSO_20200328_1630  0.054984\n",
       "6  COGMSO_20200406_0650  0.084845\n",
       "7      COGM1C7_20200131  0.031300\n",
       "8     COGM6C10_20200131  0.031300\n",
       "9     COGM1N23_20200211  0.036019"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amplitudes_final_VH.head(10)\n",
    "#amplitudes_final_VH.to_csv('amplitudes_VH_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dbb44ab3-d9e3-4bbe-b645-2187b7431ca1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pit_id</th>\n",
       "      <th>avg_amp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>COGM2S37_20200201</td>\n",
       "      <td>0.071622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>COGMSO_20200321_1006</td>\n",
       "      <td>0.123060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>COGM5S31_20200130</td>\n",
       "      <td>0.071622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>COGMCO_20200318_0825</td>\n",
       "      <td>0.103564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>COGM2C2_20200131</td>\n",
       "      <td>0.068166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>COGMSO_20200328_1630</td>\n",
       "      <td>0.123060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>COGMSO_20200406_0650</td>\n",
       "      <td>0.182058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>COGM1C7_20200131</td>\n",
       "      <td>0.074532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>COGM6C10_20200131</td>\n",
       "      <td>0.074532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>COGM1N23_20200211</td>\n",
       "      <td>0.078598</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 pit_id   avg_amp\n",
       "0     COGM2S37_20200201  0.071622\n",
       "1  COGMSO_20200321_1006  0.123060\n",
       "2     COGM5S31_20200130  0.071622\n",
       "3  COGMCO_20200318_0825  0.103564\n",
       "4      COGM2C2_20200131  0.068166\n",
       "5  COGMSO_20200328_1630  0.123060\n",
       "6  COGMSO_20200406_0650  0.182058\n",
       "7      COGM1C7_20200131  0.074532\n",
       "8     COGM6C10_20200131  0.074532\n",
       "9     COGM1N23_20200211  0.078598"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amplitudes_final_VV.head(10)\n",
    "#amplitudes_final_VV.to_csv('amplitudes_VV_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05143404-356c-4480-be4f-c0a5c46ac159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overpass Duration: 2020-02-01 02:13:16 - 2020-02-01 02:15:58 (UTC), DEM used = Intermap Elevation Model DTM, Polarization = HH\n",
      "Overpass Duration: 2020-02-01 02:13:16 - 2020-02-01 02:15:58 (UTC), DEM used = Intermap Elevation Model DTM, Polarization = HV\n",
      "Overpass Duration: 2020-02-01 02:13:16 - 2020-02-01 02:15:58 (UTC), DEM used = Intermap Elevation Model DTM, Polarization = VH\n",
      "Overpass Duration: 2020-02-01 02:13:16 - 2020-02-01 02:15:58 (UTC), DEM used = Intermap Elevation Model DTM, Polarization = VV\n"
     ]
    }
   ],
   "source": [
    "polarizations = ['HH','HV','VH','VV']\n",
    "for i in polarizations:\n",
    "    print(\"Overpass Duration: 2020-02-01 02:13:16 - 2020-02-01 02:15:58 (UTC), DEM used = Intermap Elevation Model DTM, Polarization = \"+i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5350a613-44f6-41b1-8d36-9cc326b1eccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the dataset and end the database session\n",
    "dataset.close()\n",
    "session.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
